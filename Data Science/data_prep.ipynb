{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Prep and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qt/r87857tx74n48x9wj7f9wljw0000gn/T/ipykernel_61668/2550901138.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  weather_df['timestamp'] = pd.to_datetime(weather_df['timestamp']).astype(int) // 10**9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "leak_data_raw =  pd.read_csv(\"Gasleak Data Sets/sensor_readings.csv\")\n",
    "leak_data_raw.columns = [\"temp\",\"Time\",\"Sensor 1\", \"Sensor 2\", \"Sensor 3\", \"Sensor 4\", \"Sensor 5\", \"Sensor 6\", \"Sensor 7\", \"Sensor 8\", \"Sensor 9\", \"Sensor 10\", \"Sensor 11\", \"Sensor 12\", \"Sensor 13\", \"Sensor 14\", \"Sensor 15\", \"Sensor 16\", \"Sensor 17\", \"Sensor 18\", \"Sensor 19\", \"Sensor 20\", \"Sensor 21\", \"Sensor 22\", \"Sensor 23\", \"Sensor 24\"]\n",
    "\n",
    "weather_df = pd.read_csv(\"Gasleak Data Sets/weather_data.csv\")\n",
    "columns_to_average = ['Barometric_Pressure', 'Humidity', 'Temperature', 'Wind_Direction', 'Wind_Speed']\n",
    "for col in columns_to_average:\n",
    "    weather_df[col] = weather_df.groupby('timestamp')[col].transform('mean')\n",
    "weather_df = weather_df.drop_duplicates()\n",
    "weather_df['timestamp'] = pd.to_datetime(weather_df['timestamp']).astype(int) // 10**9\n",
    "weather_df = weather_df.rename(columns={'timestamp': 'tTime'})\n",
    "\n",
    "leak_rate_df = pd.read_csv(\"Gasleak Data Sets/leak_locations_and_rate.csv\")\n",
    "leak_rate_df =  leak_rate_df[['LeakRate', 'tStart', 'tEnd', 'Duration']]\n",
    "leak_rate_df['LeakRate'] = leak_rate_df.groupby('tStart')['LeakRate'].transform('mean')\n",
    "leak_rate_df = leak_rate_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qt/r87857tx74n48x9wj7f9wljw0000gn/T/ipykernel_61668/4017535932.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1050.1875' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  leak_data_raw.iloc[i,-1] =  leak_data_raw.iloc[i, 2:-1].mean()\n"
     ]
    }
   ],
   "source": [
    "leak_data_raw['sensor_avg'] = 0\n",
    "for i in range(len(leak_data_raw)):\n",
    "    leak_data_raw.iloc[i,-1] =  leak_data_raw.iloc[i, 2:-1].mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Leak and weather data merge\n",
    "# leak_data_raw['tTime'] = leak_data_raw['Time']\n",
    "# leak_data_raw['tTime'] = pd.to_datetime(leak_data_raw['tTime'], unit='s')\n",
    "# weather_df['tTime'] = pd.to_datetime(weather_df['tTime'], unit='s')\n",
    "\n",
    "# leak_data_raw['tTime'] = leak_data_raw['tTime'].dt.floor('min').dt.round('min')\n",
    "# df = pd.merge(leak_data_raw, weather_df, on='tTime', how='left')\n",
    "# df = df.drop(['temp', 'tTime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing leak intensity\n",
    "# df['leak_amount'] = 0\n",
    "# for index, row in leak_rate_df.iterrows():\n",
    "#     in_range = df['Time'].between(row['tStart'], row['tEnd'], inclusive='both')\n",
    "#     df.loc[in_range, 'leak_amount'] = np.array((row['LeakRate'] * (row['Duration'])), dtype=np.int32)\n",
    "# df['leak_amount_norm'] = (df['leak_amount'] - df['leak_amount'].min()) / (df['leak_amount'].max() - df['leak_amount'].min())\n",
    "\n",
    "\n",
    "# # Final prep\n",
    "# df = df.drop(['leak_amount'],axis=1)\n",
    "# df = df.astype(dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = leak_data_raw.drop(['temp','Time'], axis=1)\n",
    "# df = df.astype(dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>Sensor 5</th>\n",
       "      <th>Sensor 6</th>\n",
       "      <th>Sensor 7</th>\n",
       "      <th>Sensor 8</th>\n",
       "      <th>Sensor 9</th>\n",
       "      <th>Sensor 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>Sensor 22</th>\n",
       "      <th>Sensor 23</th>\n",
       "      <th>Sensor 24</th>\n",
       "      <th>sensor_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1090.5</td>\n",
       "      <td>1039.5</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>...</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>991.5</td>\n",
       "      <td>931.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1050.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>...</td>\n",
       "      <td>765.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>928.5</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1105.5</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1049.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1022.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>975.5</td>\n",
       "      <td>974.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>...</td>\n",
       "      <td>762.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1045.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1034.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>...</td>\n",
       "      <td>762.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>1047.5</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>1059.5</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>1048.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1037.5</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>1090.5</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>...</td>\n",
       "      <td>763.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>944.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1107.5</td>\n",
       "      <td>1049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83408</th>\n",
       "      <td>853.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>...</td>\n",
       "      <td>661.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>900.5</td>\n",
       "      <td>795.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>920.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83409</th>\n",
       "      <td>852.5</td>\n",
       "      <td>899.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>788.5</td>\n",
       "      <td>900.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>...</td>\n",
       "      <td>644.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>799.5</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>917.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83410</th>\n",
       "      <td>852.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>920.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83411</th>\n",
       "      <td>859.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>...</td>\n",
       "      <td>609.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>917.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83412</th>\n",
       "      <td>855.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>...</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>913.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83413 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sensor 1  Sensor 2  Sensor 3  Sensor 4  Sensor 5  Sensor 6  Sensor 7  \\\n",
       "0        1030.0    1049.0    1166.0     964.0    1023.0    1090.5    1039.5   \n",
       "1        1033.0    1051.0    1163.0     974.0     993.0    1095.0    1044.0   \n",
       "2        1022.0    1051.0    1160.0     975.5     974.0    1081.0    1049.0   \n",
       "3        1034.0    1050.0    1165.0     977.0     988.0    1084.0    1019.0   \n",
       "4        1037.5    1049.0    1155.0     977.0     971.0    1084.0    1027.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "83408     853.0     901.0     990.0     813.0     791.0     911.0     887.0   \n",
       "83409     852.5     899.0    1007.0     801.0     788.5     900.0     890.0   \n",
       "83410     852.0     901.0    1011.0     811.0     786.0     909.0     899.0   \n",
       "83411     859.0     912.0    1010.0     811.0     764.0     909.0     892.0   \n",
       "83412     855.0     900.0    1010.0     806.0     786.0     913.0     901.0   \n",
       "\n",
       "       Sensor 8  Sensor 9  Sensor 10  ...  Sensor 16  Sensor 17  Sensor 18  \\\n",
       "0        1153.0    1082.0     1037.0  ...      735.0     1088.0      991.5   \n",
       "1        1152.0    1085.0     1039.0  ...      765.0     1090.0      984.0   \n",
       "2        1133.0    1088.0     1053.0  ...      762.0     1095.0      993.0   \n",
       "3        1128.0    1091.0     1057.0  ...      762.0     1100.0      999.0   \n",
       "4        1144.0    1090.5     1061.0  ...      763.0     1100.0     1004.5   \n",
       "...         ...       ...        ...  ...        ...        ...        ...   \n",
       "83408     943.0     968.0      966.0  ...      661.0     1037.0      900.5   \n",
       "83409     931.0     984.0      975.0  ...      644.0     1056.0      901.0   \n",
       "83410     945.0     967.0      996.0  ...      643.0     1059.0      908.0   \n",
       "83411     959.0     969.0      945.0  ...      609.0     1071.0      897.0   \n",
       "83412     962.0     958.0      945.0  ...      640.0     1078.0      904.0   \n",
       "\n",
       "       Sensor 19  Sensor 20  Sensor 21  Sensor 22  Sensor 23  Sensor 24  \\\n",
       "0          931.0     1040.0     1040.0     1111.0     1080.0     1089.0   \n",
       "1          928.5     1043.0     1052.0     1105.5     1075.0     1095.0   \n",
       "2          926.0     1039.0     1033.0     1100.0     1021.0     1093.0   \n",
       "3          929.0     1047.5     1014.0     1107.0     1059.5     1110.0   \n",
       "4          944.0     1056.0     1019.0     1098.0     1098.0     1107.5   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "83408      795.0     1007.0      955.0     1020.0      949.0      987.0   \n",
       "83409      799.5     1009.0      954.0     1018.0      955.0      986.0   \n",
       "83410      804.0     1016.0      961.0     1017.0      938.0      982.0   \n",
       "83411      802.0     1019.0      963.0     1026.0      948.0      990.0   \n",
       "83412      802.0     1019.0      953.0     1017.0      846.0      971.0   \n",
       "\n",
       "        sensor_avg  \n",
       "0      1050.187500  \n",
       "1      1049.416667  \n",
       "2      1045.083333  \n",
       "3      1048.854167  \n",
       "4      1049.000000  \n",
       "...            ...  \n",
       "83408   920.666667  \n",
       "83409   917.687500  \n",
       "83410   920.166667  \n",
       "83411   917.437500  \n",
       "83412   913.833333  \n",
       "\n",
       "[83413 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import model as m\n",
    "\n",
    "\n",
    "model = m.LightningLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor1_df_normalized = (df['Sensor 1'] - df['Sensor 1'].min()) / (df['Sensor 1'].max() - df['Sensor 1'].min())\n",
    "sensor1_df_normalized = sensor1_df_normalized.astype(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.315134\n",
       "1     0.318008\n",
       "2     0.307471\n",
       "3     0.318966\n",
       "4     0.322318\n",
       "5     0.325671\n",
       "6     0.347701\n",
       "7     0.342433\n",
       "8     0.337165\n",
       "9     0.321839\n",
       "10    0.330460\n",
       "11    0.330460\n",
       "12    0.330460\n",
       "13    0.311303\n",
       "14    0.301245\n",
       "15    0.291188\n",
       "16    0.267241\n",
       "17    0.278257\n",
       "18    0.289272\n",
       "19    0.285441\n",
       "20    0.281609\n",
       "21    0.267241\n",
       "22    0.268199\n",
       "23    0.274904\n",
       "24    0.281609\n",
       "25    0.288314\n",
       "26    0.295019\n",
       "27    0.301724\n",
       "28    0.297893\n",
       "29    0.326628\n",
       "30    0.329502\n",
       "31    0.332375\n",
       "32    0.338123\n",
       "33    0.338123\n",
       "34    0.319923\n",
       "35    0.306513\n",
       "36    0.293103\n",
       "37    0.289272\n",
       "38    0.280651\n",
       "39    0.280651\n",
       "40    0.280651\n",
       "41    0.294061\n",
       "42    0.297893\n",
       "43    0.301724\n",
       "44    0.318966\n",
       "45    0.313218\n",
       "46    0.307471\n",
       "47    0.295977\n",
       "48    0.274425\n",
       "49    0.252874\n",
       "50    0.226054\n",
       "51    0.225096\n",
       "52    0.222222\n",
       "53    0.219349\n",
       "54    0.219828\n",
       "55    0.220307\n",
       "56    0.222222\n",
       "57    0.230843\n",
       "58    0.232759\n",
       "59    0.234674\n",
       "Name: Sensor 1, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor1_df_normalized.iloc[0:60, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "labels = []\n",
    "for i in range(60, len(sensor1_df_normalized)):\n",
    "    inputs.append(sensor1_df_normalized.iloc[i-60:i, ])\n",
    "    labels.append(sensor1_df_normalized.iloc[i,])\n",
    "inputs\n",
    "inputs = torch.tensor(np.array(inputs)) # convert to numpy\n",
    "labels = torch.tensor(np.array(labels))\n",
    "\n",
    "dataset =  TensorDataset(inputs, labels) #fix dimension\n",
    "dataloader = DataLoader(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | lstm | LSTM | 16    \n",
      "------------------------------\n",
      "16        Trainable params\n",
      "0         Non-trainable params\n",
      "16        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/opt/homebrew/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 83353/83353 [08:56<00:00, 155.48it/s, v_num=23]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 83353/83353 [08:56<00:00, 155.48it/s, v_num=23]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=5)\n",
    "trainer.fit(model,train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"Gasleak Data Sets/validation_files/sensor_readings.csv\")\n",
    "test_data.columns = [\"temp\",\"Time\",\"Sensor 1\", \"Sensor 2\", \"Sensor 3\", \"Sensor 4\", \"Sensor 5\", \"Sensor 6\", \"Sensor 7\", \"Sensor 8\", \"Sensor 9\", \"Sensor 10\", \"Sensor 11\", \"Sensor 12\", \"Sensor 13\", \"Sensor 14\", \"Sensor 15\", \"Sensor 16\", \"Sensor 17\", \"Sensor 18\", \"Sensor 19\", \"Sensor 20\", \"Sensor 21\", \"Sensor 22\", \"Sensor 23\", \"Sensor 24\"]\n",
    "sensor1_test_normalized = (test_data['Sensor 1'] - test_data['Sensor 1'].min()) / (test_data['Sensor 1'].max() - test_data['Sensor 1'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the window size\n",
    "window_size = 60\n",
    "\n",
    "# Create a list of input sequences\n",
    "inputs = [sensor1_test_normalized.iloc[i:i+window_size].values for i in range(len(sensor1_test_normalized) - window_size)]\n",
    "\n",
    "# Create a list of corresponding labels\n",
    "labels = sensor1_test_normalized.iloc[window_size:].values\n",
    "\n",
    "# # Convert the lists to pandas objects\n",
    "# test_inputs = pd.DataFrame(inputs)\n",
    "# test_labels = pd.Series(labels)\n",
    "\n",
    "test_inputs = torch.tensor(np.array(inputs))\n",
    "test_labels = torch.tensor(np.array(labels))\n",
    "\n",
    "\n",
    "# prediction_df = pd.concat([test_inputs, test_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# def apply_model(x):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#     model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[39m# for i in range(len(test_inputs)):\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m prediction \u001b[39m=\u001b[39m model(test_inputs[\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/TSA Software Engenering/Data Science/model.py:12\u001b[0m, in \u001b[0;36mLightningLSTM.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m     11\u001b[0m     input_trans \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mview(\u001b[39mlen\u001b[39m(\u001b[39minput\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     lstm_out, temp  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(input_trans)\n\u001b[1;32m     14\u001b[0m     prediction \u001b[39m=\u001b[39m lstm_out[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    880\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "# def apply_model(x):\n",
    "#     model\n",
    "\n",
    "# prediction_df['prediction_normalized'] =  test_inputs.apply(lambda x: model(x).detach(), axis=0)\n",
    "# prediction_df['prediction_normalized'] = model(test_inputs[0]).detach()\n",
    "# prediction = prediction_normalized * (test_data['Sensor 1'].max() - test_data['Sensor 1'].min()) + test_data['Sensor 1'].min()\n",
    "\n",
    "# for i in range(len(test_inputs)):\n",
    "prediction = model(test_inputs[0]).detach()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path\n",
    "# trainer = L.Trainer(max_epochs=4)\n",
    "# trainer.fit(model,train_dataloaders=dataloader, ckpt_path=path_to_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# print(model(torch.tensor([848.0,850.0,855.0,854.0,855.0,853.0,852.5,852.0,859.0,855.0])).detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
