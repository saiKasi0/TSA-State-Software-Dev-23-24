{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw =  pd.read_csv(\"Gasleak Data Sets/sensor_readings.csv\")\n",
    "train_data_raw.columns = [\"temp\",\"Time\",\"Sensor 1\", \"Sensor 2\", \"Sensor 3\", \"Sensor 4\", \"Sensor 5\", \"Sensor 6\", \"Sensor 7\", \"Sensor 8\", \"Sensor 9\", \"Sensor 10\", \"Sensor 11\", \"Sensor 12\", \"Sensor 13\", \"Sensor 14\", \"Sensor 15\", \"Sensor 16\", \"Sensor 17\", \"Sensor 18\", \"Sensor 19\", \"Sensor 20\", \"Sensor 21\", \"Sensor 22\", \"Sensor 23\", \"Sensor 24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw = pd.read_csv(\"Gasleak Data Sets/validation_files/sensor_readings.csv\")\n",
    "test_data_raw.columns =  [\"temp\",\"Time\",\"Sensor 1\", \"Sensor 2\", \"Sensor 3\", \"Sensor 4\", \"Sensor 5\", \"Sensor 6\", \"Sensor 7\", \"Sensor 8\", \"Sensor 9\", \"Sensor 10\", \"Sensor 11\", \"Sensor 12\", \"Sensor 13\", \"Sensor 14\", \"Sensor 15\", \"Sensor 16\", \"Sensor 17\", \"Sensor 18\", \"Sensor 19\", \"Sensor 20\", \"Sensor 21\", \"Sensor 22\", \"Sensor 23\", \"Sensor 24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_data_raw = pd.concat([train_data_raw, test_data_raw], ignore_index=True)\n",
    "leak_data = leak_data_raw.copy()\n",
    "leak_data = leak_data.drop(['temp'], axis=1)\n",
    "leak_data['Time'] -= 1681776002\n",
    "leak_data['Sum'] = leak_data.iloc[:,1:].sum(axis=1)\n",
    "leak_data['Mean'] = leak_data.iloc[:,1:-1].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "leak_data['Normalized Sum'] = scaler.fit_transform(leak_data['Sum'].values.reshape(-1,1))\n",
    "leak_data['Normalized Mean'] = scaler.fit_transform(leak_data['Mean'].values.reshape(-1,1))\n",
    "leak_data['Normalized Sensor 1'] = scaler.fit_transform(leak_data['Sensor 1'].values.reshape(-1,1))\n",
    "\n",
    "leak_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(feature, look_back):\n",
    "    data_raw = feature.values # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length look_back\n",
    "    for index in range(len(data_raw) - look_back): \n",
    "        data.append(data_raw[index: index + look_back])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "look_back = 60 # choose sequence length\n",
    "feature =  leak_data[['Normalized Sensor 1']] # have to put in two brackets because\n",
    "x_train, y_train, x_test, y_test = load_data(feature, look_back)\n",
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m\n",
    "\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "\n",
    "model = m.LSTM(input_dim=input_dim,hidden_dim=hidden_dim,num_layers=num_layers,output_dim=output_dim)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "num_epochs = 50\n",
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim =look_back-1  \n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    #model.hidden = model.init_hidden()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_train_pred = model(x_train)\n",
    "\n",
    "    loss = loss_fn(y_train_pred, y_train)\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_pred = model(x_test)\n",
    "\n",
    "# invert predictions\n",
    "y_train_pred = scaler.inverse_transform((y_train_pred.detach()).numpy())\n",
    "y_train = scaler.inverse_transform(y_train.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test.detach().numpy())\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "figure, axes = plt.subplots(figsize=(15, 6))\n",
    "axes.xaxis_date()\n",
    "\n",
    "axes.plot(leak_data[['Normalized Sensor 1']][len(leak_data[['Normalized Sensor 1']])-len(y_test):].index, y_test, color = 'red', label = 'Real Sensor Data')\n",
    "axes.plot(leak_data[['Normalized Sensor 1']][len(leak_data[['Normalized Sensor 1']])-len(y_test):].index, y_test_pred, color = 'blue', label = 'Predicted Sensor Data')\n",
    "plt.title('Sensor 1  Prediciton')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sensor Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
